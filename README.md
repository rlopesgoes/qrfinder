# QrFinder üé¨

Sistema de an√°lise de QR Codes em v√≠deos com processamento distribu√≠do usando Kafka.

## üöÄ In√≠cio R√°pido

### Pr√©-requisitos
- Docker e Docker Compose
- Make (opcional)

### Subir o ambiente

**Com Make:**
```bash
make demo-basic
```

**Sem Make (Docker Compose apenas):**

*Ambiente B√°sico:*
```bash
# Copiar vari√°veis de ambiente
cp .env.example .env

# Subir todos os servi√ßos
docker-compose up -d

# Verificar se todos os servi√ßos est√£o rodando
docker-compose ps
```

*Ambiente Escalado (5 APIs, 10 Workers):*
```bash
# Copiar vari√°veis de ambiente
cp .env.example .env

# Subir ambiente escalado
docker-compose up -d --scale webapi=5 --scale analysis-worker=10

# Verificar se todos os servi√ßos est√£o rodando
docker-compose ps
```

### Acessar a aplica√ß√£o

- **Interface Web**: http://localhost/app/
- **API Swagger**: http://localhost/swagger/index.html
- **Kafka UI**: http://localhost:5004
- **MongoDB Express**: http://localhost:5005

## üî• Teste de Carga

O projeto inclui ferramentas para testar a escalabilidade do sistema com upload massivo de v√≠deos.

### Teste B√°sico vs Escalado

**1. Teste com ambiente b√°sico (1 worker):**
```bash
# 1. Subir ambiente b√°sico
make demo-basic

# 2. (Em terminal separado) Iniciar monitoramento
make monitor

# 3. (Em outro terminal) Executar teste de carga
make load-test
```

**2. Teste com ambiente escalado (2 workers):**
```bash
# 1. Subir ambiente escalado
make demo-scaled

# 2. (Em terminal separado) Iniciar monitoramento
make monitor

# 3. (Em outro terminal) Executar teste de carga
make load-test
```

Compare os resultados para ver a diferen√ßa de performance entre 1 worker e 2 workers processando em paralelo!

**‚ö†Ô∏è Solu√ß√£o de Problemas:**
Se os workers travarem durante o teste:
```bash
# Limpa estado e reinicia workers
make clean-state

# Ou apenas reinicia workers
make restart-workers
```

### Teste Personalizado
```bash
# Exemplo: 500 v√≠deos em 3 minutos
make load-test-custom VIDEOS=500 DURATION=3

# Exemplo: 100 v√≠deos em 1 minuto
make load-test-custom VIDEOS=100 DURATION=1
```

### Par√¢metros do Teste de Carga

**Script JavaScript (`scripts/load-test.js`)**:
- `--videos=N`: N√∫mero de v√≠deos (padr√£o: 10)
- `--duration=N`: Dura√ß√£o em minutos (padr√£o: 1)
- `--url=URL`: URL base da API (padr√£o: http://localhost/app)

**Exemplo de execu√ß√£o direta**:
```bash
node scripts/load-test.js --videos=20 --duration=2
```

### Monitoramento

O script `scripts/monitor.sh` mostra em tempo real:
- üíª **Recursos dos containers** (CPU, RAM, I/O)
- üìä **M√©tricas do Kafka** (mensagens por t√≥pico, lag dos consumers)
- üóÑÔ∏è **Estat√≠sticas do MongoDB** (documentos por cole√ß√£o)
- ‚ö° **Carga do sistema** (CPU total, mem√≥ria)

```bash
make monitor
```

### Relat√≥rios de Performance

Ap√≥s o teste, s√£o gerados:
- üìä **Console**: Relat√≥rio detalhado com m√©tricas
- üìÑ **JSON**: `scripts/load-test-results.json` com dados completos
- üìà **An√°lise**: Recomenda√ß√µes de otimiza√ß√£o

**Exemplo de relat√≥rio**:
```
üéØ LOAD TEST RESULTS
==================================================
üìä Total Videos: 60
‚úÖ Successful: 58
‚ùå Failed: 2
üìà Success Rate: 96.7%
‚è±Ô∏è  Total Duration: 1m 12s
üöÄ Actual Rate: 48 videos/min

üìã Upload Times:
   Average: 845ms
   Min: 234ms
   Max: 2567ms

üü¢ EXCELLENT: System handled load very well
```

### Paralelismo nos Workers (Opcional)

Por padr√£o, cada worker processa **1 v√≠deo por vez** para evitar travamentos. Para habilitar processamento paralelo dentro de cada worker:

**Configura√ß√£o via vari√°vel de ambiente:**
```bash
# No docker-compose.yml, adicione:
environment:
  - ANALYSISSWORKER__MAXCONCURRENCY=3
```

**Ou via appsettings.json:**
```json
{
  "AnalysisWorker": {
    "MaxConcurrency": 3
  }
}
```

‚ö†Ô∏è **Cuidado**: Paralelismo interno pode causar deadlocks em cargas altas. Prefira escalar horizontalmente (mais containers) em vez de verticalmente (mais threads por container).

### Escalabilidade Recomendada

Para diferentes volumes de v√≠deos por minuto:

| Videos/min | WebAPI | Analysis Workers | Threads/Worker | Total Capacity |
|------------|--------|------------------|----------------|----------------|
| < 50       | 1      | 2-3              | 1              | 2-3 simult√¢neos |
| 50-100     | 1-2    | 5-8              | 1              | 5-8 simult√¢neos |
| 100-200    | 2-3    | 10-15            | 1              | 10-15 simult√¢neos |
| > 200      | 3+     | 15+              | 1              | 15+ simult√¢neos |

**Comandos para escalar**:
```bash
# Escalabilidade m√©dia (100 videos/min)
make scale-all API=2 ANALYSIS=10 RESULTS=2 NOTIFICATIONS=1

# Alta escalabilidade (200+ videos/min)
make scale-all API=3 ANALYSIS=15 RESULTS=3 NOTIFICATIONS=2
```

## üì± Como Usar

1. Acesse http://localhost/app/
2. Arraste um v√≠deo ou clique para selecionar
3. Clique em "Fazer Upload e Analisar"
4. Acompanhe o progresso em tempo real
5. Veja os QR codes encontrados nos resultados

## ‚öôÔ∏è Comandos √öteis

### Com Make

```bash
# Ambiente b√°sico (1 API, 1 Worker)
make demo-basic

# Ambiente escalado (5 APIs, 10 Workers)
make demo-scaled

# Parar tudo
make stop

# Limpar volumes
make clean
```

### Sem Make

```bash
# Subir ambiente b√°sico
docker-compose up -d

# Ver logs
docker-compose logs -f

# Escalar workers e APIs
docker-compose up -d --scale webapi=5 --scale analysis-worker=10

# Parar todos os servi√ßos
docker-compose down

# Limpar volumes e dados
docker-compose down -v
docker system prune -f
```

## üèóÔ∏è Arquitetura

- **WebApp**: Interface web para upload de v√≠deos
- **WebAPI**: API REST para gerenciamento de v√≠deos
- **AnalysisWorker**: Workers que processam os v√≠deos
- **ResultsWorker**: Workers que processam resultados
- **NotificationsWorker**: Workers de notifica√ß√µes SignalR
- **SignalRServer**: Servidor de notifica√ß√µes em tempo real
- **Kafka**: Message broker para comunica√ß√£o ass√≠ncrona
- **MongoDB**: Banco de dados para armazenar metadados
- **Azurite**: Emulador do Azure Storage para v√≠deos
- **Nginx**: Proxy reverso e load balancer

## üìä Monitoramento

- **Logs em tempo real**: `docker-compose logs -f`
- **Status dos servi√ßos**: `docker-compose ps`
- **Kafka UI**: http://localhost:8082
- **MongoDB**: http://localhost:5005

## üîß Solu√ß√£o de Problemas

### Servi√ßos n√£o iniciam
```bash
# Verificar logs
docker-compose logs

# Reiniciar servi√ßos
docker-compose restart
```

### T√≥picos Kafka n√£o encontrados
```bash
# Verificar se kafka-topics-init terminou
docker-compose ps kafka-topics-init

# Ver logs da inicializa√ß√£o dos t√≥picos
docker-compose logs kafka-topics-init
```

### Problemas de upload
```bash
# Verificar se Azurite est√° rodando
docker-compose ps azurite

# Verificar logs do WebAPI
docker-compose logs webapi
```

## üõ†Ô∏è Desenvolvimento

### Rebuild de servi√ßos espec√≠ficos
```bash
# Rebuild e restart do WebAPI
docker-compose build webapi && docker-compose restart webapi

# Rebuild de todos os workers
docker-compose build analysis-worker results-worker notifications-worker
docker-compose restart analysis-worker results-worker notifications-worker
```

### Executar comandos no container
```bash
# MongoDB shell
docker exec -it qrfinder-mongo mongosh

# Kafka topics
docker exec qrfinder-kafka kafka-topics --bootstrap-server localhost:9092 --list

# Logs espec√≠ficos
docker-compose logs -f analysis-worker
```

## üìù Notas

- Todos os t√≥picos Kafka s√£o criados automaticamente com 10 parti√ß√µes
- O sistema aguarda o Kafka estar pronto antes de iniciar os workers
- Upload m√°ximo de 500MB por v√≠deo
- SignalR fornece notifica√ß√µes em tempo real do progresso
- Backup via polling caso SignalR falhe